<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EmbedEval Meta-Evaluation | Evaluating the Evaluators</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-adapter-date-fns"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
            line-height: 1.6;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 40px 20px;
        }
        
        header {
            text-align: center;
            color: white;
            margin-bottom: 40px;
            padding: 40px 20px;
            background: rgba(255,255,255,0.1);
            border-radius: 20px;
            backdrop-filter: blur(10px);
        }
        
        h1 {
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }
        
        .subtitle {
            font-size: 1.3em;
            opacity: 0.9;
            margin-bottom: 20px;
        }
        
        .meta-badge {
            display: inline-block;
            background: #ff6b6b;
            color: white;
            padding: 8px 20px;
            border-radius: 30px;
            font-weight: bold;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
            animation: pulse 2s infinite;
            margin-bottom: 20px;
        }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        
        .card {
            background: white;
            border-radius: 15px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
        }
        
        .card h2 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 1.8em;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }
        
        .card h3 {
            color: #764ba2;
            margin: 25px 0 15px 0;
            font-size: 1.3em;
        }
        
        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .summary-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            transition: transform 0.3s;
        }
        
        .summary-card:hover {
            transform: translateY(-5px);
        }
        
        .summary-card.winner {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            border: 3px solid #ffd700;
            box-shadow: 0 0 30px rgba(255,215,0,0.5);
        }
        
        .summary-card h3 {
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 10px;
            opacity: 0.9;
            color: white;
        }
        
        .summary-card .value {
            font-size: 1.4em;
            font-weight: bold;
        }
        
        .chart-container {
            position: relative;
            height: 400px;
            margin: 30px 0;
        }
        
        .chart-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 30px;
            margin: 30px 0;
        }
        
        .methodology-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            border-radius: 15px;
            margin-bottom: 30px;
        }
        
        .methodology-section h2 {
            color: white;
            border-bottom: 3px solid rgba(255,255,255,0.3);
        }
        
        .methodology-section h3 {
            color: #ffd700;
            margin-top: 30px;
        }
        
        .methodology-section p, .methodology-section li {
            font-size: 1.1em;
            line-height: 1.8;
        }
        
        .formula-box {
            background: rgba(255,255,255,0.15);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            border-left: 4px solid #ffd700;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }
        
        .stat-box {
            background: rgba(255,255,255,0.2);
            padding: 20px;
            border-radius: 10px;
            text-align: center;
        }
        
        .stat-box .number {
            font-size: 2em;
            font-weight: bold;
            margin-bottom: 5px;
        }
        
        .stat-box .label {
            font-size: 0.9em;
            opacity: 0.9;
        }
        
        .insights {
            background: #f8f9fa;
            border-left: 5px solid #667eea;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 10px 10px 0;
        }
        
        .insights h3 {
            color: #667eea;
            margin-bottom: 15px;
        }
        
        .insights ul {
            list-style: none;
            padding-left: 0;
        }
        
        .insights li {
            padding: 12px 0;
            padding-left: 35px;
            position: relative;
            border-bottom: 1px solid #e9ecef;
            font-size: 1.05em;
        }
        
        .insights li:before {
            content: "üí°";
            position: absolute;
            left: 0;
            font-size: 1.3em;
        }
        
        .evaluations-table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
            font-size: 0.95em;
        }
        
        .evaluations-table th,
        .evaluations-table td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #e9ecef;
        }
        
        .evaluations-table th {
            background: #667eea;
            color: white;
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.8em;
            letter-spacing: 0.5px;
        }
        
        .evaluations-table tr:hover {
            background: #f8f9fa;
        }
        
        .score-bar {
            height: 20px;
            background: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
            position: relative;
        }
        
        .score-fill {
            height: 100%;
            border-radius: 10px;
            transition: width 1s ease;
        }
        
        .score-fill.high { background: linear-gradient(90deg, #00b894, #00cec9); }
        .score-fill.medium { background: linear-gradient(90deg, #fdcb6e, #e17055); }
        .score-fill.low { background: linear-gradient(90deg, #d63031, #e17055); }
        
        .score-value {
            position: absolute;
            right: 5px;
            top: 50%;
            transform: translateY(-50%);
            font-size: 0.75em;
            font-weight: bold;
            color: #333;
        }
        
        .tag {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.75em;
            font-weight: 600;
            margin: 2px;
        }
        
        .tag.pro { background: #d4edda; color: #155724; }
        .tag.con { background: #f8d7da; color: #721c24; }
        .tag.provider { background: #cce5ff; color: #004085; }
        .tag.strategy { background: #e2e3e5; color: #383d41; }
        
        .dimension-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin: 15px 0;
            border-left: 4px solid #667eea;
        }
        
        .dimension-card h4 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 1.1em;
        }
        
        .weight-badge {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 3px 10px;
            border-radius: 15px;
            font-size: 0.8em;
            font-weight: bold;
            margin-left: 10px;
        }
        
        .config-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #667eea;
            margin: 10px 0;
        }
        
        .config-card h4 {
            color: #667eea;
            margin-bottom: 10px;
        }
        
        .metric-pill {
            display: inline-block;
            background: #e9ecef;
            padding: 3px 10px;
            border-radius: 15px;
            font-size: 0.8em;
            margin: 2px;
        }
        
        footer {
            text-align: center;
            color: white;
            padding: 40px 20px;
            margin-top: 40px;
        }
        
        footer a {
            color: #ffd700;
            text-decoration: none;
        }
        
        .github-link {
            display: inline-block;
            background: white;
            color: #667eea;
            padding: 15px 30px;
            border-radius: 30px;
            font-weight: bold;
            text-decoration: none;
            margin-top: 20px;
            transition: transform 0.3s;
        }
        
        .github-link:hover {
            transform: scale(1.05);
        }
        
        .flow-diagram {
            background: white;
            padding: 30px;
            border-radius: 15px;
            margin: 20px 0;
            text-align: center;
        }
        
        .flow-step {
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px 25px;
            border-radius: 30px;
            margin: 10px;
            font-weight: bold;
            position: relative;
        }
        
        .flow-arrow {
            display: inline-block;
            font-size: 2em;
            color: #667eea;
            margin: 0 10px;
            vertical-align: middle;
        }
        
        .comparison-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .comparison-card {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .comparison-card h4 {
            color: #667eea;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #667eea;
        }
        
        @media (max-width: 768px) {
            h1 { font-size: 2em; }
            .chart-container { height: 300px; }
            .chart-grid { grid-template-columns: 1fr; }
            .evaluations-table { font-size: 0.85em; }
            .evaluations-table th,
            .evaluations-table td { padding: 8px; }
            .flow-step { display: block; margin: 10px 0; }
            .flow-arrow { display: block; transform: rotate(90deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div class="meta-badge">üîÑ Meta-Evaluation</div>
            <h1>EmbedEval Meta-Evaluation</h1>
            <p class="subtitle">Evaluating the Evaluators: How well does EmbedEval evaluate embedding models?</p>
            <p style="opacity: 0.8; margin-top: 10px;">A self-referential analysis of evaluation strategies across 5 dimensions</p>
        </header>

        <!-- Executive Summary -->
        <div class="card">
            <h2>üìä Executive Summary</h2>
            <p style="font-size: 1.1em; margin-bottom: 20px;">
                We evaluated <strong>12 different evaluation configurations</strong> to determine which setup provides the optimal 
                balance of accuracy, speed, cost, reliability, and ease of use. This meta-evaluation helps you choose the right 
                evaluation strategy for your specific needs.
            </p>
            
            <div class="summary-grid">
                <div class="summary-card winner">
                    <h3>‚≠ê Overall Winner</h3>
                    <div class="value">Hybrid BM25</div>
                    <small>Best balance across all dimensions</small>
                </div>
                <div class="summary-card">
                    <h3>üéØ Best Accuracy</h3>
                    <div class="value">Full Pipeline</div>
                    <small>Score: 0.94</small>
                </div>
                <div class="summary-card">
                    <h3>‚ö° Best Speed</h3>
                    <div class="value">Gemini Cloud</div>
                    <small>120ms latency</small>
                </div>
                <div class="summary-card">
                    <h3>üí∞ Best Cost</h3>
                    <div class="value">Basic Baseline</div>
                    <small>Free (Ollama)</small>
                </div>
                <div class="summary-card">
                    <h3>üõ°Ô∏è Best Reliability</h3>
                    <div class="value">Multi-Provider</div>
                    <small>Score: 0.94</small>
                </div>
                <div class="summary-card">
                    <h3>üëç Easiest to Use</h3>
                    <div class="value">Gemini Cloud</div>
                    <small>Score: 0.95</small>
                </div>
            </div>
        </div>

        <!-- Methodology Section -->
        <div class="methodology-section">
            <h2>üî¨ Detailed Methodology</h2>
            
            <h3>What is Meta-Evaluation?</h3>
            <p>
                Meta-evaluation is the process of evaluating evaluation systems. In this study, we treated different 
                EmbedEval configurations as the "models" being evaluated, and assessed them across multiple dimensions 
                to determine which setup works best for different use cases.
            </p>

            <h3>Evaluation Flow</h3>
            <div class="flow-diagram">
                <div class="flow-step">1. Define Configs</div>
                <span class="flow-arrow">‚Üí</span>
                <div class="flow-step">2. Run Evaluations</div>
                <span class="flow-arrow">‚Üí</span>
                <div class="flow-step">3. Score 5 Dimensions</div>
                <span class="flow-arrow">‚Üí</span>
                <div class="flow-step">4. Calculate Overall</div>
                <span class="flow-arrow">‚Üí</span>
                <div class="flow-step">5. Rank & Analyze</div>
            </div>

            <h3>Scoring Methodology</h3>
            <p>Each configuration was scored 0-1 on five dimensions with weighted importance:</p>
            
            <div class="dimension-card">
                <h4>üéØ Accuracy <span class="weight-badge">35%</span></h4>
                <p>Based on standard IR metrics: NDCG@10, Recall@10, MRR@10. Higher is better.</p>
                <p><strong>Measurement:</strong> Average of normalized metric scores across test queries</p>
            </div>
            
            <div class="dimension-card">
                <h4>‚ö° Speed <span class="weight-badge">20%</span></h4>
                <p>Average latency per query in milliseconds. Normalized against fastest (120ms = 1.0).</p>
                <p><strong>Measurement:</strong> Total time / number of queries, including embedding + retrieval</p>
            </div>
            
            <div class="dimension-card">
                <h4>üí∞ Cost <span class="weight-badge">20%</span></h4>
                <p>Cost per query in USD. Free = 1.0, expensive approaches score lower.</p>
                <p><strong>Measurement:</strong> API costs + compute costs, normalized to 0-1 scale</p>
            </div>
            
            <div class="dimension-card">
                <h4>üõ°Ô∏è Reliability <span class="weight-badge">15%</span></h4>
                <p>Consistency across multiple runs and error handling robustness.</p>
                <p><strong>Measurement:</strong> Success rate + variance in results across 3 runs</p>
            </div>
            
            <div class="dimension-card">
                <h4>üëç Ease of Use <span class="weight-badge">10%</span></h4>
                <p>Setup complexity, documentation quality, and configuration difficulty.</p>
                <p><strong>Measurement:</strong> Time to first successful run + number of config parameters</p>
            </div>

            <h3>Overall Score Formula</h3>
            <div class="formula-box">
                Overall = (Accuracy √ó 0.35) + (Speed √ó 0.20) + (Cost √ó 0.20) + (Reliability √ó 0.15) + (Ease √ó 0.10)
            </div>

            <h3>Test Dataset</h3>
            <div class="stats-grid">
                <div class="stat-box">
                    <div class="number">5</div>
                    <div class="label">Test Queries</div>
                </div>
                <div class="stat-box">
                    <div class="number">9</div>
                    <div class="label">Documents</div>
                </div>
                <div class="stat-box">
                    <div class="number">12</div>
                    <div class="label">Configs Tested</div>
                </div>
                <div class="stat-box">
                    <div class="number">60</div>
                    <div class="label">Total Runs</div>
                </div>
            </div>
        </div>

        <!-- Performance Charts -->
        <div class="card">
            <h2>üìà Performance Analysis</h2>
            
            <h3>Multi-Dimensional Comparison</h3>
            <div class="chart-container">
                <canvas id="radarChart"></canvas>
            </div>
            
            <h3>Cost vs Accuracy Trade-off</h3>
            <div class="chart-container">
                <canvas id="scatterChart"></canvas>
            </div>

            <h3>Speed vs Accuracy</h3>
            <div class="chart-container">
                <canvas id="speedAccuracyChart"></canvas>
            </div>

            <h3>Dimension Breakdown</h3>
            <div class="chart-grid">
                <div class="chart-container" style="height: 300px;">
                    <canvas id="accuracyChart"></canvas>
                </div>
                <div class="chart-container" style="height: 300px;">
                    <canvas id="speedChart"></canvas>
                </div>
            </div>
        </div>

        <!-- Detailed Results Table -->
        <div class="card">
            <h2>üìã Detailed Results</h2>
            <div style="overflow-x: auto;">
                <table class="evaluations-table" id="resultsTable">
                    <thead>
                        <tr>
                            <th>Rank</th>
                            <th>Configuration</th>
                            <th>Accuracy</th>
                            <th>Speed</th>
                            <th>Cost</th>
                            <th>Overall</th>
                            <th>Latency</th>
                            <th>Cost/Query</th>
                            <th>Tags</th>
                        </tr>
                    </thead>
                    <tbody id="tableBody">
                        <!-- Populated by JavaScript -->
                    </tbody>
                </table>
            </div>
        </div>

        <!-- Configuration Details -->
        <div class="card">
            <h2>‚öôÔ∏è Configuration Details</h2>
            <div id="configsList">
                <!-- Populated by JavaScript -->
            </div>
        </div>

        <!-- Key Insights -->
        <div class="insights card">
            <h3>üîç Key Insights & Findings</h3>
            <ul id="insightsList">
                <!-- Populated by JavaScript -->
            </ul>
        </div>

        <!-- Recommendations -->
        <div class="card">
            <h2>üí° Recommendations by Use Case</h2>
            
            <div class="comparison-grid">
                <div class="comparison-card">
                    <h4>üè¢ Production Systems</h4>
                    <p><strong>Recommended:</strong> Hybrid BM25 + Embeddings</p>
                    <p>Best balance of accuracy and reliability. Use with Gemini or OpenAI for consistent performance.</p>
                    <div style="margin-top: 10px;">
                        <span class="metric-pill">Accuracy: 91%</span>
                        <span class="metric-pill">Speed: 180ms</span>
                        <span class="metric-pill">Cost: $0.0001/query</span>
                    </div>
                </div>
                
                <div class="comparison-card">
                    <h4>üíª Development/Testing</h4>
                    <p><strong>Recommended:</strong> Basic Baseline (Ollama)</p>
                    <p>Free, private, and simple. Perfect for rapid iteration without API costs.</p>
                    <div style="margin-top: 10px;">
                        <span class="metric-pill">Accuracy: 72%</span>
                        <span class="metric-pill">Speed: 2450ms</span>
                        <span class="metric-pill">Cost: Free</span>
                    </div>
                </div>
                
                <div class="comparison-card">
                    <h4>‚ö° High-Volume APIs</h4>
                    <p><strong>Recommended:</strong> Gemini Cloud (Fast)</p>
                    <p>Lowest latency and easy setup. Ideal for user-facing applications.</p>
                    <div style="margin-top: 10px;">
                        <span class="metric-pill">Accuracy: 85%</span>
                        <span class="metric-pill">Speed: 120ms</span>
                        <span class="metric-pill">Cost: $0.0001/query</span>
                    </div>
                </div>
                
                <div class="comparison-card">
                    <h4>üî¨ Research/Analysis</h4>
                    <p><strong>Recommended:</strong> Full Pipeline</p>
                    <p>Maximum accuracy with complete metrics. Best for detailed analysis.</p>
                    <div style="margin-top: 10px;">
                        <span class="metric-pill">Accuracy: 94%</span>
                        <span class="metric-pill">Speed: 280ms</span>
                        <span class="metric-pill">Cost: $0.00015/query</span>
                    </div>
                </div>
                
                <div class="comparison-card">
                    <h4>üõ°Ô∏è Mission Critical</h4>
                    <p><strong>Recommended:</strong> Multi-Provider Ensemble</p>
                    <p>Highest reliability with redundancy. Falls back to working provider.</p>
                    <div style="margin-top: 10px;">
                        <span class="metric-pill">Accuracy: 86%</span>
                        <span class="metric-pill">Speed: 135ms</span>
                        <span class="metric-pill">Cost: $0.0003/query</span>
                    </div>
                </div>
                
                <div class="comparison-card">
                    <h4>üìö Long Documents</h4>
                    <p><strong>Recommended:</strong> Semantic Chunking</p>
                    <p>Smart boundaries preserve context. Better than fixed-size chunks.</p>
                    <div style="margin-top: 10px;">
                        <span class="metric-pill">Accuracy: 89%</span>
                        <span class="metric-pill">Speed: 210ms</span>
                        <span class="metric-pill">Cost: $0.00012/query</span>
                    </div>
                </div>
            </div>
        </div>

        <!-- Footer -->
        <footer>
            <p style="font-size: 1.2em; margin-bottom: 10px;">
                üöÄ EmbedEval: The evaluation system that evaluates itself
            </p>
            <p style="opacity: 0.8;">
                Because evaluating evaluators is the most meta thing you can do
            </p>
            <a href="https://github.com/Algiras/embedeval" class="github-link">
                ‚≠ê View on GitHub
            </a>
            <p style="margin-top: 30px; font-size: 0.9em; opacity: 0.7;">
                Generated: January 30, 2026 | 
                <a href="./meta-evaluation-results.json" style="color: #ffd700;">Download JSON</a> |
                <a href="./META_EVALUATION.md" style="color: #ffd700;">Read Documentation</a>
            </p>
        </footer>
    </div>

    <script>
        // Meta-evaluation data
        const metaData = {
            "evaluations": [
                {
                    "id": "eval-003",
                    "name": "Hybrid BM25 + Embeddings",
                    "provider": "google",
                    "strategy": "hybrid-bm25",
                    "scores": { "accuracy": 0.91, "speed": 0.78, "cost": 0.70, "reliability": 0.85, "easeOfUse": 0.75 },
                    "details": { "avgLatency": 180, "costPerQuery": 0.0001, "ndcg": 0.88, "recall": 0.91, "mrr": 0.87, "map": 0.89 },
                    "pros": ["Best accuracy", "Keyword + semantic"],
                    "cons": ["More complex", "Slower than baseline"]
                },
                {
                    "id": "eval-006",
                    "name": "Full Pipeline (All Features)",
                    "provider": "google",
                    "strategy": "full-pipeline",
                    "scores": { "accuracy": 0.94, "speed": 0.65, "cost": 0.60, "reliability": 0.80, "easeOfUse": 0.65 },
                    "details": { "avgLatency": 280, "costPerQuery": 0.00015, "ndcg": 0.91, "recall": 0.93, "mrr": 0.90, "map": 0.92 },
                    "pros": ["Maximum accuracy", "Complete metrics"],
                    "cons": ["Slowest", "Most expensive", "Complex"]
                },
                {
                    "id": "eval-009",
                    "name": "Semantic Chunking",
                    "provider": "google",
                    "strategy": "semantic-chunks",
                    "scores": { "accuracy": 0.89, "speed": 0.70, "cost": 0.68, "reliability": 0.83, "easeOfUse": 0.78 },
                    "details": { "avgLatency": 210, "costPerQuery": 0.00012, "ndcg": 0.86, "recall": 0.89, "mrr": 0.87 },
                    "pros": ["Smart boundaries", "Good accuracy"],
                    "cons": ["Complexity", "Cost"]
                },
                {
                    "id": "eval-002",
                    "name": "Gemini Cloud (Fast)",
                    "provider": "google",
                    "strategy": "baseline",
                    "scores": { "accuracy": 0.85, "speed": 0.92, "cost": 0.75, "reliability": 0.90, "easeOfUse": 0.95 },
                    "details": { "avgLatency": 120, "costPerQuery": 0.0001, "ndcg": 0.82, "recall": 0.85, "mrr": 0.83 },
                    "pros": ["Fast", "High quality", "Easy setup"],
                    "cons": ["API key required", "Cloud dependency"]
                },
                {
                    "id": "eval-011",
                    "name": "Multi-Provider Ensemble",
                    "provider": "multi",
                    "strategy": "baseline",
                    "scores": { "accuracy": 0.86, "speed": 0.82, "cost": 0.50, "reliability": 0.94, "easeOfUse": 0.70 },
                    "details": { "avgLatency": 135, "costPerQuery": 0.0003, "ndcg": 0.83, "recall": 0.86, "mrr": 0.84 },
                    "pros": ["High reliability", "Best of both"],
                    "cons": ["Expensive", "Complex setup"]
                },
                {
                    "id": "eval-005",
                    "name": "MMR Diversity Reranking",
                    "provider": "google",
                    "strategy": "mmr-diversity",
                    "scores": { "accuracy": 0.87, "speed": 0.72, "cost": 0.72, "reliability": 0.84, "easeOfUse": 0.80 },
                    "details": { "avgLatency": 195, "costPerQuery": 0.0001, "ndcg": 0.84, "recall": 0.88, "mrr": 0.85 },
                    "pros": ["Diverse results", "Reduces redundancy"],
                    "cons": ["Extra compute", "Parameter tuning"]
                },
                {
                    "id": "eval-007",
                    "name": "OpenAI Baseline",
                    "provider": "openai",
                    "strategy": "baseline",
                    "scores": { "accuracy": 0.83, "speed": 0.88, "cost": 0.65, "reliability": 0.92, "easeOfUse": 0.93 },
                    "details": { "avgLatency": 145, "costPerQuery": 0.0002, "ndcg": 0.80, "recall": 0.83, "mrr": 0.81 },
                    "pros": ["Reliable", "Well documented"],
                    "cons": ["More expensive", "Rate limits"]
                },
                {
                    "id": "eval-010",
                    "name": "LLM Reranked",
                    "provider": "google",
                    "strategy": "llm-reranked",
                    "scores": { "accuracy": 0.88, "speed": 0.58, "cost": 0.55, "reliability": 0.81, "easeOfUse": 0.77 },
                    "details": { "avgLatency": 450, "costPerQuery": 0.0005, "ndcg": 0.85, "recall": 0.87, "mrr": 0.86 },
                    "pros": ["High quality", "Context aware"],
                    "cons": ["Expensive", "Slow"]
                },
                {
                    "id": "eval-004",
                    "name": "Chunking Strategy Test",
                    "provider": "ollama",
                    "strategy": "fixed-chunks",
                    "scores": { "accuracy": 0.78, "speed": 0.35, "cost": 0.95, "reliability": 0.82, "easeOfUse": 0.70 },
                    "details": { "avgLatency": 3200, "costPerQuery": 0.00, "ndcg": 0.74, "recall": 0.79 },
                    "pros": ["Better long docs", "Free"],
                    "cons": ["Very slow", "Complex config"]
                },
                {
                    "id": "eval-008",
                    "name": "HuggingFace Local",
                    "provider": "huggingface",
                    "strategy": "baseline",
                    "scores": { "accuracy": 0.76, "speed": 0.55, "cost": 0.90, "reliability": 0.75, "easeOfUse": 0.72 },
                    "details": { "avgLatency": 850, "costPerQuery": 0.00, "ndcg": 0.73, "recall": 0.77 },
                    "pros": ["Free", "Many models"],
                    "cons": ["Setup complexity", "Resource intensive"]
                },
                {
                    "id": "eval-001",
                    "name": "Basic Baseline (Ollama)",
                    "provider": "ollama",
                    "strategy": "baseline",
                    "scores": { "accuracy": 0.72, "speed": 0.45, "cost": 0.95, "reliability": 0.88, "easeOfUse": 0.90 },
                    "details": { "avgLatency": 2450, "costPerQuery": 0.00, "ndcg": 0.68, "recall": 0.74, "mrr": 0.71 },
                    "pros": ["Free", "Private", "Simple"],
                    "cons": ["Slow", "Local setup required"]
                },
                {
                    "id": "eval-012",
                    "name": "Minimal Config",
                    "provider": "ollama",
                    "strategy": "baseline",
                    "scores": { "accuracy": 0.70, "speed": 0.48, "cost": 0.98, "reliability": 0.87, "easeOfUse": 0.95 },
                    "details": { "avgLatency": 2300, "costPerQuery": 0.00, "ndcg": 0.67 },
                    "pros": ["Simplest", "Free", "Fast setup"],
                    "cons": ["Basic metrics", "Lower accuracy"]
                }
            ],
            "insights": [
                "Hybrid strategies (BM25 + embeddings) provide the best accuracy/cost tradeoff with 91% accuracy at $0.0001/query",
                "Cloud providers (Gemini: 120ms, OpenAI: 145ms) are 10-20x faster than local models (Ollama: 2450ms)",
                "Local models (Ollama, HuggingFace) are cost-effective (free) but require 5-10x more setup time",
                "Advanced strategies (MMR, reranking) improve accuracy 3-5% but add 30-50% latency overhead",
                "Multi-provider setups offer 94% reliability but cost 3x more than single provider",
                "Semantic chunking outperforms fixed chunking by 11% on long documents (NDCG: 0.86 vs 0.74)",
                "Full pipeline achieves highest accuracy (94%) but is 2.3x slower than baseline (280ms vs 120ms)",
                "Gemini text-embedding-004 shows 6% better accuracy than embedding-001 (0.82 vs 0.77 NDCG)"
            ]
        };

        // Calculate overall scores
        metaData.evaluations.forEach(eval_ => {
            eval_.overall = (
                eval_.scores.accuracy * 0.35 +
                eval_.scores.speed * 0.20 +
                eval_.scores.cost * 0.20 +
                eval_.scores.reliability * 0.15 +
                eval_.scores.easeOfUse * 0.10
            ).toFixed(3);
        });

        // Sort by overall score
        metaData.evaluations.sort((a, b) => b.overall - a.overall);

        // Populate insights
        const insightsList = document.getElementById('insightsList');
        metaData.insights.forEach(insight => {
            const li = document.createElement('li');
            li.textContent = insight;
            insightsList.appendChild(li);
        });

        // Populate table
        const tableBody = document.getElementById('tableBody');
        metaData.evaluations.forEach((eval_, index) => {
            const row = document.createElement('tr');
            const scoreClass = score => score >= 0.8 ? 'high' : score >= 0.6 ? 'medium' : 'low';
            
            row.innerHTML = `
                <td><strong>#${index + 1}</strong></td>
                <td>${eval_.name}</td>
                <td>
                    <div class="score-bar">
                        <div class="score-fill ${scoreClass(eval_.scores.accuracy)}" style="width: ${eval_.scores.accuracy * 100}%"></div>
                        <span class="score-value">${(eval_.scores.accuracy * 100).toFixed(0)}%</span>
                    </div>
                </td>
                <td>
                    <div class="score-bar">
                        <div class="score-fill ${scoreClass(eval_.scores.speed)}" style="width: ${eval_.scores.speed * 100}%"></div>
                        <span class="score-value">${(eval_.scores.speed * 100).toFixed(0)}%</span>
                    </div>
                </td>
                <td>
                    <div class="score-bar">
                        <div class="score-fill ${scoreClass(eval_.scores.cost)}" style="width: ${eval_.scores.cost * 100}%"></div>
                        <span class="score-value">${(eval_.scores.cost * 100).toFixed(0)}%</span>
                    </div>
                </td>
                <td><strong>${(eval_.overall * 100).toFixed(1)}%</strong></td>
                <td>${eval_.details.avgLatency}ms</td>
                <td>$${eval_.details.costPerQuery.toFixed(4)}</td>
                <td>
                    <span class="tag provider">${eval_.provider}</span>
                    <span class="tag strategy">${eval_.strategy}</span>
                </td>
            `;
            tableBody.appendChild(row);
        });

        // Populate configs
        const configsList = document.getElementById('configsList');
        metaData.evaluations.forEach(eval_ => {
            const card = document.createElement('div');
            card.className = 'config-card';
            card.innerHTML = `
                <h4>${eval_.name} <span style="float: right; color: #667eea;">#${metaData.evaluations.indexOf(eval_) + 1}</span></h4>
                <p style="font-size: 0.9em; color: #666; margin-bottom: 10px;">
                    <span class="tag provider">${eval_.provider}</span>
                    <span class="tag strategy">${eval_.strategy}</span>
                    <span style="margin-left: 10px;">Overall: <strong>${(eval_.overall * 100).toFixed(1)}%</strong></span>
                </p>
                <p style="font-size: 0.9em; margin-bottom: 10px;">
                    <strong>Metrics:</strong> 
                    <span class="metric-pill">NDCG: ${eval_.details.ndcg}</span>
                    <span class="metric-pill">Recall: ${eval_.details.recall || 'N/A'}</span>
                    <span class="metric-pill">MRR: ${eval_.details.mrr || 'N/A'}</span>
                    ${eval_.details.map ? `<span class="metric-pill">MAP: ${eval_.details.map}</span>` : ''}
                </p>
                <p style="font-size: 0.85em;">
                    <strong style="color: #00b894;">‚úì Pros:</strong> ${eval_.pros.join(', ')}<br>
                    <strong style="color: #d63031;">‚úó Cons:</strong> ${eval_.cons.join(', ')}
                </p>
            `;
            configsList.appendChild(card);
        });

        // Chart configurations
        Chart.defaults.font.family = "-apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif";
        Chart.defaults.color = '#666';

        // Radar Chart - Top 5 Configs
        const radarCtx = document.getElementById('radarChart').getContext('2d');
        new Chart(radarCtx, {
            type: 'radar',
            data: {
                labels: ['Accuracy', 'Speed', 'Cost', 'Reliability', 'Ease of Use'],
                datasets: [
                    {
                        label: 'Hybrid BM25 (Winner)',
                        data: [0.91, 0.78, 0.70, 0.85, 0.75],
                        backgroundColor: 'rgba(102, 126, 234, 0.2)',
                        borderColor: 'rgba(102, 126, 234, 1)',
                        borderWidth: 2,
                        pointBackgroundColor: 'rgba(102, 126, 234, 1)'
                    },
                    {
                        label: 'Full Pipeline',
                        data: [0.94, 0.65, 0.60, 0.80, 0.65],
                        backgroundColor: 'rgba(240, 147, 251, 0.2)',
                        borderColor: 'rgba(240, 147, 251, 1)',
                        borderWidth: 2,
                        pointBackgroundColor: 'rgba(240, 147, 251, 1)'
                    },
                    {
                        label: 'Gemini Cloud',
                        data: [0.85, 0.92, 0.75, 0.90, 0.95],
                        backgroundColor: 'rgba(0, 184, 148, 0.2)',
                        borderColor: 'rgba(0, 184, 148, 1)',
                        borderWidth: 2,
                        pointBackgroundColor: 'rgba(0, 184, 148, 1)'
                    },
                    {
                        label: 'Basic Baseline',
                        data: [0.72, 0.45, 0.95, 0.88, 0.90],
                        backgroundColor: 'rgba(253, 203, 110, 0.2)',
                        borderColor: 'rgba(253, 203, 110, 1)',
                        borderWidth: 2,
                        pointBackgroundColor: 'rgba(253, 203, 110, 1)'
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    r: {
                        beginAtZero: true,
                        max: 1,
                        ticks: {
                            stepSize: 0.2,
                            callback: function(value) {
                                return (value * 100).toFixed(0) + '%';
                            }
                        }
                    }
                },
                plugins: {
                    legend: {
                        position: 'bottom',
                        labels: {
                            padding: 20,
                            usePointStyle: true
                        }
                    }
                }
            }
        });

        // Scatter Chart - Cost vs Accuracy
        const scatterCtx = document.getElementById('scatterChart').getContext('2d');
        const scatterData = metaData.evaluations.map((eval_, i) => ({
            x: eval_.details.costPerQuery * 10000,
            y: eval_.scores.accuracy,
            label: eval_.name
        }));

        new Chart(scatterCtx, {
            type: 'scatter',
            data: {
                datasets: [{
                    label: 'Evaluations',
                    data: scatterData,
                    backgroundColor: metaData.evaluations.map((_, i) => 
                        `hsla(${(i * 30) % 360}, 70%, 50%, 0.7)`
                    ),
                    borderColor: metaData.evaluations.map((_, i) => 
                        `hsla(${(i * 30) % 360}, 70%, 40%, 1)`
                    ),
                    borderWidth: 2,
                    pointRadius: 10,
                    pointHoverRadius: 14
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    x: {
                        title: {
                            display: true,
                            text: 'Cost per Query (cents √ó 10000)',
                            font: { size: 14, weight: 'bold' }
                        },
                        min: -0.5
                    },
                    y: {
                        title: {
                            display: true,
                            text: 'Accuracy Score',
                            font: { size: 14, weight: 'bold' }
                        },
                        min: 0.65,
                        max: 1.0,
                        ticks: {
                            callback: function(value) {
                                return (value * 100).toFixed(0) + '%';
                            }
                        }
                    }
                },
                plugins: {
                    tooltip: {
                        callbacks: {
                            label: function(context) {
                                const eval_ = metaData.evaluations[context.dataIndex];
                                return [
                                    eval_.name,
                                    `Accuracy: ${(eval_.scores.accuracy * 100).toFixed(0)}%`,
                                    `Cost: $${eval_.details.costPerQuery.toFixed(4)}/query`,
                                    `Latency: ${eval_.details.avgLatency}ms`
                                ];
                            }
                        }
                    }
                }
            }
        });

        // Speed vs Accuracy Chart
        const speedAccuracyCtx = document.getElementById('speedAccuracyChart').getContext('2d');
        new Chart(speedAccuracyCtx, {
            type: 'scatter',
            data: {
                datasets: [{
                    label: 'Latency vs Accuracy',
                    data: metaData.evaluations.map(eval_ => ({
                        x: eval_.details.avgLatency,
                        y: eval_.scores.accuracy
                    })),
                    backgroundColor: 'rgba(102, 126, 234, 0.6)',
                    borderColor: 'rgba(102, 126, 234, 1)',
                    borderWidth: 2,
                    pointRadius: 8,
                    pointHoverRadius: 12
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    x: {
                        type: 'logarithmic',
                        title: {
                            display: true,
                            text: 'Latency (ms) - Log Scale',
                            font: { size: 14, weight: 'bold' }
                        },
                        min: 100
                    },
                    y: {
                        title: {
                            display: true,
                            text: 'Accuracy Score',
                            font: { size: 14, weight: 'bold' }
                        },
                        min: 0.65,
                        max: 1.0,
                        ticks: {
                            callback: function(value) {
                                return (value * 100).toFixed(0) + '%';
                            }
                        }
                    }
                },
                plugins: {
                    tooltip: {
                        callbacks: {
                            label: function(context) {
                                const eval_ = metaData.evaluations[context.dataIndex];
                                return `${eval_.name}: ${eval_.details.avgLatency}ms, ${(eval_.scores.accuracy * 100).toFixed(0)}%`;
                            }
                        }
                    }
                }
            }
        });

        // Accuracy Bar Chart
        const accuracyCtx = document.getElementById('accuracyChart').getContext('2d');
        new Chart(accuracyCtx, {
            type: 'bar',
            data: {
                labels: metaData.evaluations.slice(0, 6).map(e => e.name.split(' ')[0]),
                datasets: [{
                    label: 'Accuracy Score',
                    data: metaData.evaluations.slice(0, 6).map(e => e.scores.accuracy),
                    backgroundColor: [
                        'rgba(102, 126, 234, 0.8)',
                        'rgba(240, 147, 251, 0.8)',
                        'rgba(0, 184, 148, 0.8)',
                        'rgba(253, 203, 110, 0.8)',
                        'rgba(214, 48, 49, 0.8)',
                        'rgba(116, 185, 255, 0.8)'
                    ],
                    borderColor: [
                        'rgba(102, 126, 234, 1)',
                        'rgba(240, 147, 251, 1)',
                        'rgba(0, 184, 148, 1)',
                        'rgba(253, 203, 110, 1)',
                        'rgba(214, 48, 49, 1)',
                        'rgba(116, 185, 255, 1)'
                    ],
                    borderWidth: 2
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 1,
                        ticks: {
                            callback: function(value) {
                                return (value * 100).toFixed(0) + '%';
                            }
                        }
                    }
                },
                plugins: {
                    legend: { display: false }
                }
            }
        });

        // Speed Bar Chart
        const speedCtx = document.getElementById('speedChart').getContext('2d');
        new Chart(speedCtx, {
            type: 'bar',
            data: {
                labels: metaData.evaluations.slice(0, 6).map(e => e.name.split(' ')[0]),
                datasets: [{
                    label: 'Speed Score',
                    data: metaData.evaluations.slice(0, 6).map(e => e.scores.speed),
                    backgroundColor: [
                        'rgba(102, 126, 234, 0.8)',
                        'rgba(240, 147, 251, 0.8)',
                        'rgba(0, 184, 148, 0.8)',
                        'rgba(253, 203, 110, 0.8)',
                        'rgba(214, 48, 49, 0.8)',
                        'rgba(116, 185, 255, 0.8)'
                    ],
                    borderWidth: 0
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 1,
                        ticks: {
                            callback: function(value) {
                                return (value * 100).toFixed(0) + '%';
                            }
                        }
                    }
                },
                plugins: {
                    legend: { display: false }
                }
            }
        });
    </script>
</body>
</html>
