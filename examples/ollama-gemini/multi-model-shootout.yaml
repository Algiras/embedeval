# Comprehensive Multi-Model Evaluation
# Tests multiple Ollama embedding models + LLMs vs Gemini permutations
# This is the "kitchen sink" evaluation - test everything!

test:
  name: "Comprehensive Multi-Model Shootout"
  description: "Compare all available Ollama embedding models and LLMs against Gemini permutations"
  tags: ["comprehensive", "multi-model", "ollama", "gemini", "llm"]

variants:
  # ============================================
  # OLLAMA EMBEDDING MODELS
  # ============================================
  
  # 1. Nomic Embed Text (Most popular, good balance)
  - id: ollama-nomic-baseline
    name: "Ollama: nomic-embed-text + Baseline"
    provider:
      type: ollama
      model: nomic-embed-text
    strategy: baseline
    description: "Most popular Ollama embedding model"

  - id: ollama-nomic-chunks
    name: "Ollama: nomic-embed-text + Semantic Chunks"
    provider:
      type: ollama
      model: nomic-embed-text
    strategy: semantic-chunks
    description: "Nomic with intelligent chunking"

  - id: ollama-nomic-hybrid
    name: "Ollama: nomic-embed-text + Hybrid BM25"
    provider:
      type: ollama
      model: nomic-embed-text
    strategy: hybrid-bm25
    description: "Nomic + keyword matching"

  # 2. All-MiniLM (Lightweight, fast)
  - id: ollama-minilm-baseline
    name: "Ollama: all-minilm + Baseline"
    provider:
      type: ollama
      model: all-minilm
    strategy: baseline
    description: "Lightweight 22M parameter model"

  - id: ollama-minilm-chunks
    name: "Ollama: all-minilm + Semantic Chunks"
    provider:
      type: ollama
      model: all-minilm
    strategy: semantic-chunks
    description: "Fast model with chunking"

  # 3. MXBAI Embed Large (High quality, larger)
  - id: ollama-mxbai-baseline
    name: "Ollama: mxbai-embed-large + Baseline"
    provider:
      type: ollama
      model: mxbai-embed-large
    strategy: baseline
    description: "High quality 334M parameter model"

  # 4. Snowflake Arctic Embed (Latest, high performing)
  - id: ollama-snowflake-baseline
    name: "Ollama: snowflake-arctic-embed + Baseline"
    provider:
      type: ollama
      model: snowflake-arctic-embed
    strategy: baseline
    description: "State-of-the-art Ollama embeddings"

  - id: ollama-snowflake-chunks
    name: "Ollama: snowflake-arctic-embed + Semantic Chunks"
    provider:
      type: ollama
      model: snowflake-arctic-embed
    strategy: semantic-chunks
    description: "Best Ollama model with chunking"

  # ============================================
  # OLLAMA LLM RERANKING (Uses LLM to rerank)
  # ============================================
  
  # Using LLM for reranking with different models
  - id: ollama-nomic-llm-rerank
    name: "Ollama: nomic-embed + llama3.2 reranking"
    provider:
      type: ollama
      model: nomic-embed-text
    strategy: llm-reranked
    llmProvider:
      type: ollama
      model: llama3.2
    description: "Embeddings + LLM reranking"

  - id: ollama-nomic-qwen-rerank
    name: "Ollama: nomic-embed + qwen2.5 reranking"
    provider:
      type: ollama
      model: nomic-embed-text
    strategy: llm-reranked
    llmProvider:
      type: ollama
      model: qwen2.5
    description: "Embeddings + Qwen LLM reranking"

  # ============================================
  # GEMINI PERMUTATIONS
  # ============================================
  
  # Gemini with different models
  - id: gemini-004-baseline
    name: "Gemini: text-embedding-004 + Baseline"
    provider:
      type: google
      model: text-embedding-004
    strategy: baseline
    description: "Latest Gemini embedding model"

  - id: gemini-004-chunks
    name: "Gemini: text-embedding-004 + Semantic Chunks"
    provider:
      type: google
      model: text-embedding-004
    strategy: semantic-chunks
    description: "Gemini with chunking"

  - id: gemini-004-hybrid
    name: "Gemini: text-embedding-004 + Hybrid BM25"
    provider:
      type: google
      model: text-embedding-004
    strategy: hybrid-bm25
    description: "Gemini + keyword matching"

  - id: gemini-004-mmr
    name: "Gemini: text-embedding-004 + MMR Diversity"
    provider:
      type: google
      model: text-embedding-004
    strategy: mmr-diversity
    description: "Gemini with diversity reranking"

  - id: gemini-004-full
    name: "Gemini: text-embedding-004 + Full Pipeline"
    provider:
      type: google
      model: text-embedding-004
    strategy: full-pipeline
    description: "Gemini with all optimizations"

  # Gemini with different embedding sizes
  - id: gemini-001-baseline
    name: "Gemini: embedding-001 + Baseline"
    provider:
      type: google
      model: embedding-001
    strategy: baseline
    description: "Legacy Gemini model for comparison"

  # ============================================
  # HYBRID APPROACHES
  # ============================================
  
  # Ollama embeddings + Gemini LLM for reranking
  - id: hybrid-ollama-embed-gemini-llm
    name: "Hybrid: Ollama embeddings + Gemini LLM rerank"
    provider:
      type: ollama
      model: nomic-embed-text
    strategy: llm-reranked
    llmProvider:
      type: google
      model: gemini-pro
    description: "Free embeddings + Cloud LLM reranking"

  # Multi-stage: Ollama for retrieval, Gemini for reranking
  - id: hybrid-cascade
    name: "Hybrid: Ollama retrieve + Gemini rerank cascade"
    provider:
      type: ollama
      model: nomic-embed-text
    strategy: cascade
    rerankProvider:
      type: google
      model: text-embedding-004
    description: "Two-stage: Ollama retrieval, Gemini reranking"

  # ============================================
  # ENSEMBLE APPROACHES
  # ============================================
  
  # Multiple Ollama models ensemble
  - id: ollama-ensemble
    name: "Ollama Ensemble: nomic + minilm + mxbai"
    providers:
      - type: ollama
        model: nomic-embed-text
      - type: ollama
        model: all-minilm
      - type: ollama
        model: mxbai-embed-large
    strategy: ensemble
    fusion: reciprocal-rank
    description: "Combine multiple Ollama models"

  # Ollama + Gemini ensemble
  - id: mixed-ensemble
    name: "Mixed Ensemble: Ollama + Gemini"
    providers:
      - type: ollama
        model: nomic-embed-text
      - type: google
        model: text-embedding-004
    strategy: ensemble
    fusion: weighted
    weights: [0.4, 0.6]
    description: "Best of both worlds"

  # ============================================
  # COST-OPTIMIZED
  # ============================================
  
  # Best free option
  - id: best-free
    name: "Best Free: snowflake-arctic-embed + hybrid"
    provider:
      type: ollama
      model: snowflake-arctic-embed
    strategy: hybrid-bm25
    description: "Highest quality free option"

  # Best value (quality per dollar)
  - id: best-value
    name: "Best Value: Gemini-004 + baseline"
    provider:
      type: google
      model: text-embedding-004
    strategy: baseline
    description: "Best quality per dollar"

dataset: ./examples/data/sample-queries.jsonl
corpus: ./examples/data/sample-corpus.jsonl

metrics:
  - ndcg@10
  - ndcg@5
  - recall@10
  - recall@5
  - mrr@10
  - precision@5
  - map@10

output:
  json: ./results/multi-model-shootout/metrics.json
  dashboard: ./results/multi-model-shootout/dashboard.html
  sideBySide: ./results/multi-model-shootout/comparison.html
  csv: ./results/multi-model-shootout/results.csv

cache:
  maxSizeGB: 20
  checkpointInterval: 5

# This is a comprehensive evaluation - expect it to take 2-4 hours
# Total variants: ~25
# With 100 queries each: 2,500 total queries
# Estimated cost: $15-25 (mostly Gemini calls)
# Estimated time: 2-4 hours (can run overnight)

# To pull Ollama models before running:
# ollama pull nomic-embed-text
# ollama pull all-minilm
# ollama pull mxbai-embed-large
# ollama pull snowflake-arctic-embed
# ollama pull llama3.2
# ollama pull qwen2.5
