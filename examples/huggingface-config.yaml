# Example: Comparing Hugging Face Models
# This configuration compares different Hugging Face embedding models

providers:
  # Hugging Face via Inference API (requires API key)
  - type: huggingface
    model: sentence-transformers/all-MiniLM-L6-v2
    apiKey: ${HUGGINGFACE_API_KEY}
    useInferenceAPI: true
  
  # Another HF model
  - type: huggingface
    model: sentence-transformers/all-mpnet-base-v2
    apiKey: ${HUGGINGFACE_API_KEY}
    useInferenceAPI: true
  
  # Local Hugging Face model via custom endpoint (e.g., Text Embeddings Inference)
  # - type: huggingface
  #   model: BAAI/bge-large-en-v1.5
  #   endpoint: http://localhost:8080  # TEI or TGI endpoint
  
  # Compare with OpenAI
  - type: openai
    apiKey: ${OPENAI_API_KEY}
    model: text-embedding-3-small

strategies:
  - name: baseline
    pipeline: [embed, retrieve]

metrics:
  - ndcg@5
  - ndcg@10
  - recall@5
  - recall@10
  - mrr@10

dataset: ./examples/sample-queries.jsonl
corpus: ./examples/sample-corpus.jsonl

output:
  json: ./results/hf-comparison.json
  dashboard: ./results/hf-comparison.html

cache:
  maxSizeGB: 10
  checkpointInterval: 1
